#+TITLE: *Modelling the effects of domestication in Wheat through novel computer vision techniques*
#+OPTIONS: title:nil toc:nil H:4 author:nil date:nil TeX:t LaTeX:t  ^:nil
#+EXPORT_SELECT_TAGS: export
#+EXPORT_EXCLUDE_TAGS: noexport
#+INCLUDE: "./preamble.org"


* Introduction, Analysis and Objectives

This project aims to answer a biological research question through the use of computer science, whilst also creating a software suite which will enable further studies to be carried out with ease.

Primarily the focus has been on the data science elements of my degree, creating, cleaning and discerning meaning in it.

Using a population of genetically diverse wheat, several hypothesis and questions are explored in the hopes of contributing to the scientific understanding of domestication. A mixture of image analysis through three-dimensional micro-computed tomography and computational analysis are used to provide these much needed solutions.

Additionally, as this is very much multi-disciplinary research, specific terms and definitions have been outlined in the /glossary/ (table:[[tab:glossary]]).

** Background

Western society and agriculture has been dominated by the ability to create successful crops for the past 10,000 years cite:Ozkan2002. Of these crops wheat is considered to be one of the most vital and is estimated to contribute to 20% of the total calories and proteins consumed worldwide, and accounts for roughly 53% of total harvested area (in China and Central Asia) cite:Shiferaw2013.

During domestication, the main traits selected for breeding were most likely plant height and yield. This meant that important non-expressed traits such as disease resistance and drought tolerance were often neglected and lost overtime.

Whilst the choices made for selective breeding were successful, effects are now being felt as it is estimated that as much as a 5% dip is observed yearly on wheat production cite:Shiferaw2013. This decrease in efficiency is attributed to climate change bringing in more hostile conditions, which these elite and thoroughly domesticated genotypes are unprepared for.

Modern breeding programs have had some success in selecting primitive undomesticated genotypes and using them to breed back in useful alleles which would have been lost during domestication cite:Charmet2011.

As such, there are questions still left open about how best to make selections for crop breeding. There is also a lack of formalised modelling of information which could be of use to these areas of research.

** Biological Question and Materials

The driving question for this research asks "Can \micro-CT data be used to model domestication in wheat?". Using an already grown and harvested range of genetically diverse wheat this project has generated a collection of 3D images, processed these images into raw phenotypic data and produced biologically significant information. The biological data used in this solution are as follows:

The population of wheat used contains samples from the following genotypes:

#+BEGIN_LaTeX
  \begin{multicols}{3}

    \begin{itemize}
    \item Wild Monococcum (2N)
    \item Domesticated Monococcum (2N)
    \item Tauschii (2N)
    \end{itemize}

    \columnbreak

    \begin{itemize}
    \item Durum (4N)
    \item Dicoccoides (4N)
    \item Dicoccum (4N)
    \item Ispahanicum (4N)
    \item Timopheevii (4N)
    \end{itemize}

    \columnbreak

    \begin{itemize}
    \item Spelta(6N)
    \item Aestivum (6N)
    \item Compactum (6N)
    \end{itemize}

  \end{multicols}

#+END_LaTeX

These samples come from over 70 plants and provided in excess of 2000 seeds for analysis which data was created based on. The traits recorded are labelled in figure:[[fig:seeds]] and are as follows:

#+BEGIN_LaTeX
  \begin{multicols}{2}

    \begin{itemize}
    \item Length
    \item Width
    \item Depth

    \end{itemize}

    \columnbreak

    \begin{itemize}
    \item Volume
    \item Surface Area
    \item Crease Depth / Volume
    \end{itemize}


  \end{multicols}

#+END_LaTeX


#+CAPTION: Wheat grain labelled (/left/), wheat grain cut in half (/right/)
#+ATTR_LATEX: :width 17cm
#+NAME: fig:seeds
[[./images/seeds.png]]

** Significance to Current Research
The biological interest in this area has been expressed in several areas of research cite:Leigh2013, it is proposed that the key to unlocking diversity in the wheat genus lies in these ancestor, undomesticated species cite:Cockram2007.

This research has the potential to be useful in several areas including: crop breeding; disease resistance; environmental stress.

The individual images in figure:[[fig:phylo]] show, at a glance, the diversity and also the difference in the wild and cultivated (domesticated)
species. This work allows for these differences to be quantified and evaluated into useful metrics for answering research based questions.

#+CAPTION: Phylogeny of wheat genotypes (Provided by Dr. Hugo Oliveira)
#+ATTR_LATEX: :width 17cm
#+NAME: fig:phylo
[[file:./images/philotree.png]]

** Aim and Objectives

The overarching aim of this project has been to create several pieces of software which aid in answering the biologically significant questions outlined. As well as to prove/disprove the hypothesis stated below.

The software created is robust in order to duplicate results and is flexible as to allow for further studies to be carried out and to use the same method.

Novel additions have been made to existing image analysis libraries in order to make them more flexible for this project. Figure:[[fig:spikes]] illustrates the range of diversity

#+CAPTION: Two \micro-CT scans of wheat spikes, showing diversity in Population, Compactum (6N) left, Durum right (4N)
#+ATTR_LATEX: :width 11cm
#+NAME: fig:spikes
[[./images/spikes.png]]


Furthermore, the library written allows for easy data organisation and automation of otherwise difficult tasks such as concatenating data from multiple sources and graphing of information. Full documentation and integrated testing allows for a suite of tools which can be built upon in future and reduce the amount of effort required for similar studies to be carried out and analysed.

These aims have a focus on the phenotypic attributes generated from customised image analysis software cite:Hughes2017 and can be seen in figure:[[fig:seeds]].

** Hypothesis
To provide a full spectrum of analysis the null-hypothesis of this work is presented as investigating if there are morphometric differences in the seeds of several wheat varieties outlined in figure:[[fig:phylo]].

The comparison pairs are as follows:

1. Monococcum Wild and Monococcum Domesticate
2. Dicoccoides and Dicoccum
3. Spelta and Aestivum
4. Dicoccum and Durum
5. Monococcum Wild and Dicoccoides

** Problems Overview

The problems which this project tackles come in two flavours: Computational and Biological. As such keen awareness of these is needed to appreciate the novelty of this work.

*** Biological Problems
Previous studies have been able to demonstrate that variation in wheat grain morphology can be partially explained, in 2010 Gegas et al. demonstrated this through a 99.4% 2 component PCA cite:Gegas2010. However there is much left to do in terms of formal classifications and descriptions of these differences. This project deals with this problem through computational analysis.

Two effects run parallel in this study which requires acute biological knowledge of in order to make correct decisions:

1. The effects of ploidy in wheat.
2. The effects of domestication in wheat.

Hypothesis are required to take into account, both of these effects so as not to misidentify results.

*** Computational Problems
Using \micro-CT data in plant sciences is becoming more and more common cite:Tracy2017,Jhala2015,Hughes2017,Metzner2015 and whilst a lot of studies focus on the traits of grains specifically no formal model has been created, no accepted data format. This is a data engineering problem and the methods described in this project address this.

Further to data organisation, proposals are made for the statistical analysis which should be used. This allows for studies to become more robust and repeatable, thus strengthening the studies overall.

The biological material used in this research is much more diverse a population than has been previously studied with \micro-CT image analysis, this requires current computer vision methods to be adapted in order to be accurate.

** Deliverables

This project provides three final deliveribles:

1. A flexible software suite written in /Python/ that provides a standardised method for analysing and interpreting \micro-CT data output.
2. A Graphical User Interface (GUI) which offers a point and click method for data gathering, graphing and manipulating \micro-CT data, using the library from deliverable 1 as a backend.
3. Answers to the proposed questions (hypothesis), the /Results/ and /Discussion/ sections of this report provides this.

* Software Design, Implementation and Testing
This project made use of formal design methods and strict organisation whilst being flexible to change.
Overall the design took a hybridised form in order to best suit the scientific environment which this
domain specific software is built for.

** Software Development Methodology
Data analysis drove the direction of the project, as a result an agile methodology was adopted.
Weekly sprints were implemented as a list of "todo's", these were written on a Monday morning based off of the
previous week's list.

Critical self-evaluation was performed by means of a "one-man SCRUM" meeting, this is a technique which requires self-discipline in order to accurately find faults and areas for improvement.

** Functional Requirements
*** Requirements for CT Analysing Library
*** Requirements for CT GUI Application
- Useable by /anyone/
** Version control
** Designing Process
** Documentation
The provided CT Analysing Library comes with "human-readable" format. Where most documentation generators (Doxygen, Pydocs, Javadocs etc.) implement very well structured and comprehensive documentation, the output is generally not very friendly and easy to read. Particularly for non-career-programmers. A core feature of these provided software implementations are that they are well suited for a biologist, researcher or statistician to use.

This documentation generator was purpose created, implemented in LISP and provided in listing:[[lst:docgen]].

Beyond this, inline commenting is provided for supplied software. Keeping in line with the agile development ethos the software is self-documented and self-evident. A brief example of this is shown in listing:[[lst:docexample]]

Similarly, the documentation for using the CT GUI Application is based on feedback provided via user testing and Google form feedback data.
** Language Choice
** Software Library Choices
** Implementation

** Testing
*** Feedback Forms
Feedback and constructive suggestions were made by researchers at the National Plant Phenomics Centre, these were submitted via the Google forms service...
*** Unit Testing CT Analysing Library

#+ATTR_LATEX: :environment tabularx :width \textwidth :align |l|X|r|
#+NAME: tab:unittest
#+CAPTION: Output of /pytest/ Unit Tests and results for CT Analysing Library
|---------------------------+----------------------------------------------------+------------|
| *Result*                  | *Test*                                             | *Duration* |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | CTData.py::test_aggregate_spike_averages           |       0.03 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | CTData.py::test_clean_data_maximum_removed         |       0.00 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | CTData.py::test_clean_data_minimum_removed         |       0.00 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | CTData.py::test_load_additional_data               |       1.30 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | CTData.py::test_load_additional_data_no_data       |       0.00 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | CTData.py::test_load_data                          |       0.13 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | CTData.py::test_NoDataFoundException               |       0.00 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Data_transforms.py::test_box_cox_data              |       0.01 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Data_transforms.py::test_pca_to_table              |       0.01 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Data_transforms.py::test_perform_pca               |       0.02 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Data_transforms.py::test_standardise_data          |       0.01 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Graphing.py::test_plot_boxplot_as_dataframe        |       0.05 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Graphing.py::test_plot_boxplot_as_object           |       0.05 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Graphing.py::test_plot_difference_of_means         |       0.11 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Graphing.py::test_plot_histogram_as_dataframe      |       0.02 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Graphing.py::test_plot_histogram_as_object         |       0.02 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Graphing.py::test_plot_pca                         |       0.17 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Graphing.py::test_plot_qqplot                      |       0.00 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Statistical_tests.py::test_baysian_hypothesis_test |      10.76 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Statistical_tests.py::test_t_test                  |       0.00 |
|---------------------------+----------------------------------------------------+------------|
| \color{ForestGreen}Passed | Statistical_tests.py::test_test_normality          |       0.00 |
|---------------------------+----------------------------------------------------+------------|

*** Unit Testing CT GUI Application
* Methods and Solutions
** Data Pipeline

#+NAME: fig:matlab
#+BEGIN_SRC  plantuml :results file :file ./images/matlab.png
(*) -> "Scan wheat Spikes"

partition MATLAB {
--> "Load Raw Scan Data"
-> "Convert to 2D Image Stacks"
--> "Calculate Threshold Percentile"
-left-> "Segment and Mask via Threshold"
--> "Calculate 3D Quasi-Euclidean Distance"
If "Seeds Joined" then
--> [Yes] "Separate by Watershed"
--> "Detect Objects"
else
-> [No] "Detect Objects"
Endif



-> "Record Measurements"
--> [For each seed] "Record Measurements"

--> "Output Data to CSV format"
}
->(*)

#+END_SRC
#+BEGIN_CENTER
#+CAPTION: Image Processing Pipeline
#+ATTR_LATEX: :width 10cm
#+NAME: fig:matlab
[[file:./images/matlab.png]]
#+RESULTS: fig:matlab
#+END_CENTER

** Image Analysis Methods
***  New Watershed Algorithm

In order to solve the problem of misidentified and joint seeds, from the primitive collection,
a  /quasi-euclidean/ distance transform was implemented into the analysis pipeline (figure:[[fig:matlab]]). This provided much better results than the previous
/chessboard/ transform which had been successful on more uniform data in previous studies cite:Hughes2017.

**** Quasi-Euclidean algorithm

This algorithm measures the total euclidean distance along a set of horizontal, vertical and diagonal
line segments cite:Pfaltz1966.

#+NAME: eqn:qe
\begin{equation}
\left | x_1 - x_2 \right | + (\sqrt{2}-1), \left | x_1 - x_2 \right | >\left | y_1 - y_2 \right | (\sqrt{2}-1) \left | x_1 - x_2 \right | ,\textup{otherwise}
\end{equation}


In order to apply this to a 3D space Kleinberg's method is used  cite:Kleinberg1997. This allows for nearest neighbour pixels to be sorted by $k$-dimensional trees
and enabling fast distance transforms via Rosenfeld and Pfaltz's /quasi-euclidean/ method stated in equation:[[eqn:qe]].
**** Effect of Enhanced Watershed algorithm
#+BEGIN_CENTER
#+CAPTION: /A/ showing the chessboard method, /B/ improved quasi-euclidean method
#+ATTR_LATEX: :width 10cm
#+NAME: fig:qe
[[./images/chess_quasi.png]]
#+END_CENTER

** CT Analysing Library Methods
** CT GUI Application Methods
** Data Analysis Methods
#+NAME: fig:pipeline
#+BEGIN_SRC  plantuml :results file :file ./images/pipeline.png

(*) -> "MATLAB Output"
partition Python {
-right-> "Load and Convert data to CTData Objects"

If "Check for \nfalse positives?" then
-> [Yes]"Estimate Error"
--> "Remove Estimated Outliers"
--> "Load in external experiment information"
else
-> [No] "Load in external experiment information"
Endif

If "Spike Joining?" then
-left-> [Yes] "Process logical spike joining"
--> "Aggregate Data columns"
else
--> [No] "Aggregate Data columns"
Endif

If "Normally Distributed?" then
--> [Yes] "Perform Parametric Tests"

--> "Output Results"
else
--> [No] "Perform Non-Parametric Tests"
Endif

--> "Output Results"
}
#+END_SRC
#+BEGIN_CENTER
#+CAPTION: How data is integrated with the CT Analysing Library
#+ATTR_LATEX: :width 10cm
#+NAME: fig:pipeline
[[file:./images/pipeline.png]]
#+RESULTS: fig:pipeline
#+END_CENTER

* Results
* Discussion
** Similar Research
** Alternate Solutions

* Critical Evaluation
** Organisational Methods
** Relevance to Degree
** Time Management
** Collaborative Work
** Other Issues

* Appendix
** /Software Packages Used/

*** Libraries
#+ATTR_LATEX: :environment tabularx :width \textwidth :align |X|X|X|
#+NAME: tab:software
#+CAPTION: Software libraries used
|---------------------------------+-------+------------|
| MATLAB Image Processing Toolbox | Numpy | Matplotlib |
|---------------------------------+-------+------------|
| Seaborn                         | Scipy | Sklearn    |
|---------------------------------+-------+------------|
| Statsmodels                     | Pymc3 | Xlrd       |
|---------------------------------+-------+------------|
| PyQt5                           |       |            |
|---------------------------------+-------+------------|

*** Tools
#+ATTR_LATEX: :environment tabularx :width \textwidth :align |X|X|X|
#+NAME: tab:softwareused
#+CAPTION: Software tools used
|--------+-----------------------+----------|
| MATLAB | Python Debugger (PDB) | IPython  |
|--------+-----------------------+----------|
| Emacs  | git                   | org-mode |
|--------+-----------------------+----------|
| Tomviz | ImageJ                |          |
|--------+-----------------------+----------|

** /Glossary/
#+ATTR_LATEX: :environment tabularx :width \textwidth :align |l|X|
#+NAME: tab:glossary
#+CAPTION: Dictionary for Terms and acronyms
|--------------+------------------------------------------------------------------------------|
| *Term*       | *Definition*                                                                 |
|--------------+------------------------------------------------------------------------------|
| \micro-CT    | Micro Computed Tomography                                                    |
|--------------+------------------------------------------------------------------------------|
| Genotype     | A genetically distinct individual or group                                   |
|--------------+------------------------------------------------------------------------------|
| Phenotype    | A physical/measurable trait                                                  |
|--------------+------------------------------------------------------------------------------|
| Alleles      | A variant of a gene                                                          |
|--------------+------------------------------------------------------------------------------|
| Genus        | Classification ranking, below the /family/ grouping                          |
|--------------+------------------------------------------------------------------------------|
| Genome       | The complete genetic make up of an organism, which defines its individuality |
|--------------+------------------------------------------------------------------------------|
| Morphometric | The shape and form of an organism                                            |
|--------------+------------------------------------------------------------------------------|
| GUI          | Graphical User Interface                                                     |
|--------------+------------------------------------------------------------------------------|
| PCA          | Principal Component Analysis                                                 |
|--------------+------------------------------------------------------------------------------|


** /Code Segments and Examples/
*** MATLAB Watershedding

#+CAPTION: MATLAB Watershedding function
#+LABEL: lst:ws
#+BEGIN_SRC octave
  function [W] = watershedSplit3D(A)
    % Takes image stack A and splits it into stack W
    % Convert to BW
    bw = logical(A);
    % Create variable for opening and closing
    se = strel('disk', 5);
    % Minimise object missshapen-ness
    bw = imerode(bw, se);
    bw = imdilate(bw, se);
    % Fill in any left over holes
    bw = imfill(bw,4,'holes');
    % Use chessboard for distance calculation for more refined splitting
    chessboard = -bwdist(~bw, 'quasi-euclidean');
    % Modify the intensity of our bwdist to produce chessboard2
    mask = imextendedmin(chessboard, 2);
    chessboard2 = imimposemin(chessboard, mask);
    % Calculate watershed based on the modified chessboard
    Ld2 = watershed(chessboard2);
    % Take original image and add on the lines calculated for splitting
    W = A;
    W(Ld2 == 0) = 0;
  end
#+END_SRC

*** Custom Documentation Generator
#+CAPTION: Custom lisp code for generating easy to read documentation
#+LABEL: lst:docgen
#+BEGIN_SRC emacs-lisp
  (defun populate-org-buffer (buffer filename root)
    (goto-char (point-min))
    (let ((to-insert (concat "* " (replace-regexp-in-string root "" filename) "\n") ))
      (while (re-search-forward
	      (rx (group (or "def" "class"))
		  space
		  (group (+ (not (any "()"))))
		  (? "(" (* nonl) "):" (+ "\n") (+ space)
		     (= 3 "\"")
		     (group (+? anything))
		     (= 3 "\"")))
	      nil 'noerror)
	(setq to-insert
	      (concat
	       to-insert
	       (if (string= "class" (match-string 1))
		   "** "
		 "*** ")
	       (match-string 2)
	       "\n"
	       (and (match-string 3)
		    (concat (match-string 3) "\n")))))
      (with-current-buffer buffer
	(insert to-insert))))

  (defun org-documentation-from-dir (&optional dir)
    (interactive)
    (let* ((dir  (or dir (read-directory-name "Choose base directory: ")))
	   (files (directory-files-recursively dir "\py$"))
	   (doc-buf (get-buffer-create "org-docs")))
      (dolist (file files)
	(with-temp-buffer
	  (insert-file-contents file)
	  (populate-org-buffer doc-buf file dir)))
      (with-current-buffer doc-buf
	(org-mode))))
#+END_SRC

\clearpage
*** Self-Documenting Code Example
#+CAPTION: Example of code documentation and readability from /data_transforms.py/
#+LABEL: lst:docexample
#+BEGIN_SRC python
  def get_spike_info(self, excel_file, join_column='Folder#'):
      """
      This function should do something akin to adding additional
      information to the data frame

      @note there is some confusion in the NPPC about whether to use
      folder name or file name as the unique id when this is made into
      end-user software, a toggle should be added to allow this

      @param excel_file a file to attach and read data from
      @param join_column if the column for joining data is
      different then it should be stated
      """
      try:
	  # Grab the linking excel file
	  info = pd.read_excel(excel_file,
			       index_col='Folder#')

	  features = list(info.columns)
	  # Lambda to look up the feature in excel spreadsheet
	  def look_up(x, y): return info.loc[x['folderid']][y]

	  # Lambda form a series (data row) and apply it to dataframe
	  def gather_data(x): return pd.Series(
	      [look_up(x, y) for y in features])

	  self.df[features] = self.df.apply(gather_data, axis=1)
      except KeyError as e:
	  print('Error matching data')
	  print(e)
	  raise NoDataFoundException
      except AttributeError as e:
	  print(e)
	  raise NoDataFoundException

#+END_SRC

\clearpage
bibliography:library.bib
bibliographystyle:IEEEannotU
